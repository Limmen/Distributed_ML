{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tSession 3355 unexpectedly reached final status 'dead'. See logs:\n",
      "stdout: \n",
      "17/12/23 14:50:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "17/12/23 14:50:04 INFO RMProxy: Connecting to ResourceManager at /10.0.104.190:8032\n",
      "17/12/23 14:50:04 INFO Client: Requesting a new application from cluster with 30 NodeManagers\n",
      "17/12/23 14:50:04 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (216000 MB per container)\n",
      "17/12/23 14:50:04 INFO Client: Will allocate AM container, with 56320 MB memory including 5120 MB overhead\n",
      "17/12/23 14:50:04 INFO Client: Setting up container launch context for our AM\n",
      "17/12/23 14:50:04 INFO Client: Setting up the launch environment for our AM container\n",
      "17/12/23 14:50:04 INFO Client: Preparing resources for our AM container\n",
      "17/12/23 14:50:05 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "17/12/23 14:50:08 INFO Client: Uploading resource file:/tmp/spark-a69376fc-cab3-4c36-9636-52debcd8817e/__spark_libs__7906098837884017942.zip -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/__spark_libs__7906098837884017942.zip\n",
      "17/12/23 14:50:09 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/livy-rsc-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/livy-rsc-0.4.0-SNAPSHOT.jar\n",
      "17/12/23 14:50:09 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/netty-all-4.0.29.Final.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/netty-all-4.0.29.Final.jar\n",
      "17/12/23 14:50:09 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/livy-api-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/livy-api-0.4.0-SNAPSHOT.jar\n",
      "17/12/23 14:50:09 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/livy-repl_2.11-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/livy-repl_2.11-0.4.0-SNAPSHOT.jar\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/livy-core_2.11-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/livy-core_2.11-0.4.0-SNAPSHOT.jar\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/commons-codec-1.9.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/commons-codec-1.9.jar\n",
      "17/12/23 14:50:10 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/har_2__kimham00/har_2__kimham00__kstore.jks#k_certificate\n",
      "17/12/23 14:50:10 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/har_2__kimham00/har_2__kimham00__tstore.jks#t_certificate\n",
      "17/12/23 14:50:10 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/spark/log4j.properties\n",
      "17/12/23 14:50:10 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/har_2__kimham00/har_2__kimham00__cert.key#material_passwd\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/srv/hops/spark/python/lib/pyspark.zip -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/pyspark.zip\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/srv/hops/spark/python/lib/py4j-0.10.4-src.zip -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/py4j-0.10.4-src.zip\n",
      "17/12/23 14:50:10 WARN Client: Same path resource file:/srv/hops/spark/python/lib/pyspark.zip added multiple times to distributed cache.\n",
      "17/12/23 14:50:10 WARN Client: Same path resource file:/srv/hops/spark/python/lib/py4j-0.10.4-src.zip added multiple times to distributed cache.\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/tmp/spark-a69376fc-cab3-4c36-9636-52debcd8817e/__spark_conf__232271761179586674.zip -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/__spark_conf__.zip\n",
      "17/12/23 14:50:10 INFO SecurityManager: Changing view acls to: livy,har_2__kimham00\n",
      "17/12/23 14:50:10 INFO SecurityManager: Changing modify acls to: livy,har_2__kimham00\n",
      "17/12/23 14:50:10 INFO SecurityManager: Changing view acls groups to: \n",
      "17/12/23 14:50:10 INFO SecurityManager: Changing modify acls groups to: \n",
      "17/12/23 14:50:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(livy, har_2__kimham00); groups with view permissions: Set(); users  with modify permissions: Set(livy, har_2__kimham00); groups with modify permissions: Set()\n",
      "17/12/23 14:50:10 INFO Client: Submitting application application_1513605045578_0638 to ResourceManager\n",
      "17/12/23 14:50:10 INFO YarnClientImpl: Submitted application application_1513605045578_0638\n",
      "17/12/23 14:50:10 INFO Client: Application report for application_1513605045578_0638 (state: ACCEPTED)\n",
      "17/12/23 14:50:11 INFO Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: AM container is launched, waiting for AM container to Register with RM\n",
      "\t ApplicationMaster host: N/A\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: default\n",
      "\t start time: 1514037010972\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://hadoop30:8088/proxy/application_1513605045578_0638/\n",
      "\t user: har_2__kimham00\n",
      "17/12/23 14:50:11 INFO ShutdownHookManager: Shutdown hook called\n",
      "17/12/23 14:50:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-a69376fc-cab3-4c36-9636-52debcd8817e\n",
      "\n",
      "stderr: \n",
      "\n",
      "YARN Diagnostics: \n",
      "YARN Diagnostics:\n",
      "Application application_1513605045578_0638 failed 1 times (global limit =2; local limit is =1) due to AM Container for appattempt_1513605045578_0638_000001 exited with  exitCode: -1\n",
      "Failing this attempt.Diagnostics: Failed to create cgroup at /sys/fs/cgroup/devices/hops-yarn/container_e28_1513605045578_0638_01_000001\n",
      "For more detailed output, check the application tracking page: http://hadoop30:8088/cluster/app/application_1513605045578_0638 Then click on links to logs of each attempt.\n",
      ". Failing the application..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "def map_fun(args, ctx):\n",
    "    \"\"\"Training/Inference Function executed by parameter-servers and workers in distributed TFOS\"\"\"\n",
    "    from tensorflowonspark import TFNode\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    import time\n",
    "    from hops import tensorboard\n",
    "    from datetime import datetime\n",
    "    import pydoop.hdfs as pyhdfs\n",
    "    from tensorflow.python.tools import freeze_graph\n",
    "    startTime= datetime.now()\n",
    "\n",
    "    # Constants\n",
    "    NUM_FEATURES = 3\n",
    "    NUM_CLASSES = 7\n",
    "    SEQUENCE_SIZE = 200\n",
    "    NUM_HIDDEN_UNITS = 64\n",
    "    TEST_SIZE = 130622\n",
    "    TRAIN_SIZE = 522490\n",
    "    LEARNING_RATE = args.learningrate\n",
    "\n",
    "    def print_log(worker_num, arg):\n",
    "        print(\"Worker {0}: {1}\".format(worker_num, arg))\n",
    "\n",
    "    # Cluster parameters\n",
    "    worker_num = ctx.worker_num\n",
    "    job_name = ctx.job_name\n",
    "    task_index = ctx.task_index\n",
    "    cluster_spec = ctx.cluster_spec\n",
    "    print_log(worker_num, \"task_index: {0}, job_name {1}, cluster_spec: {2}\".format(task_index, job_name, cluster_spec))\n",
    "    num_workers = len(cluster_spec['worker'])\n",
    "\n",
    "    # Delay PS nodes a bit, since workers seem to reserve GPUs more quickly/reliably (w/o conflict)\n",
    "    if job_name == \"ps\":\n",
    "        time.sleep((worker_num + 1) * 5)\n",
    "\n",
    "    batch_size = 10024\n",
    "    print_log(worker_num, \"batch_size: {0}\".format(batch_size))\n",
    "\n",
    "    # Get TF cluster and server instances\n",
    "    cluster, server = TFNode.start_cluster_server(ctx, 1, args.rdma)\n",
    "\n",
    "    def read_csv_features(feature_dir, batch_size=100, num_epochs=None, task_index=None, num_workers=None):\n",
    "        \"\"\" Reads pre-processed and parallelized CSV files from disk into TF-HDFS queues\"\"\"\n",
    "        print_log(worker_num, \"num_epochs: {0}\".format(num_epochs))\n",
    "\n",
    "        # Setup queue of csv feature filenames\n",
    "        tf_record_pattern = os.path.join(feature_dir, 'part-*')\n",
    "        features = tf.gfile.Glob(tf_record_pattern)\n",
    "        print_log(worker_num, \"features: {0}\".format(features))\n",
    "        feature_queue = tf.train.string_input_producer(features, shuffle=False, capacity=1000, num_epochs=num_epochs,\n",
    "                                                       name=\"feature_queue\")\n",
    "        # Setup reader for feature queue\n",
    "        feature_reader = tf.TextLineReader(name=\"feature_reader\")\n",
    "        _, feat_csv = feature_reader.read(feature_queue)\n",
    "        feature_defaults = [[1.0] for col in range(SEQUENCE_SIZE * NUM_FEATURES)]\n",
    "        feature = tf.stack(tf.decode_csv(feat_csv, feature_defaults), name=\"input_features\")\n",
    "        print_log(worker_num, \"features: {0}, shape: {1}\".format(feature, feature.shape))\n",
    "\n",
    "        # Return a batch of examples\n",
    "        return tf.train.batch([feature], batch_size, num_threads=1, name=\"batch_csv\")\n",
    "\n",
    "    def read_csv_labels(label_dir, batch_size=10, num_epochs=None, task_index=None, num_workers=None):\n",
    "        \"\"\" Reads pre-processed and parallelized CSV files from disk into TF-HDFS queues\"\"\"\n",
    "        print_log(worker_num, \"num_epochs: {0}\".format(num_epochs))\n",
    "\n",
    "        # Setup queue of csv label filenames\n",
    "        tf_record_pattern = os.path.join(label_dir, 'part-*')\n",
    "        labels = tf.gfile.Glob(tf_record_pattern)\n",
    "        print_log(worker_num, \"labels: {0}\".format(labels))\n",
    "        label_queue = tf.train.string_input_producer(labels, shuffle=False, capacity=1000, num_epochs=num_epochs,\n",
    "                                                     name=\"label_queue\")\n",
    "        # Setup reader for label queue\n",
    "        label_reader = tf.TextLineReader(name=\"label_reader\")\n",
    "        _, label_csv = label_reader.read(label_queue)\n",
    "        label_defaults = [tf.constant([], dtype=tf.int64)]\n",
    "        label = tf.stack(tf.decode_csv(label_csv, label_defaults), name=\"input_labels\")\n",
    "        print_log(worker_num, tf.shape(label))\n",
    "        print_log(worker_num, \"label: {0}\".format(label))\n",
    "\n",
    "        # Return a batch of examples\n",
    "        return tf.train.batch([label], batch_size, num_threads=1, name=\"label_batch_csv\")\n",
    "    \n",
    "    def save_model(sess):\n",
    "        tf.train.write_graph(sess.graph_def, args.model, 'har.pbtxt')  \n",
    "        saver.save(sess, save_path = args.model + \"/har.ckpt\")\n",
    "        MODEL_NAME = 'har'\n",
    "\n",
    "        input_graph_path = args.model + MODEL_NAME+'.pbtxt'\n",
    "        checkpoint_path = args.model +MODEL_NAME+'.ckpt'\n",
    "        restore_op_name = \"save/restore_all\"\n",
    "        filename_tensor_name = \"save/Const:0\"\n",
    "        output_frozen_graph_name = 'frozen_'+MODEL_NAME+'.pb'\n",
    "\n",
    "        freeze_graph.freeze_graph(input_graph_path, input_saver=\"\",\n",
    "                          input_binary=False, input_checkpoint=checkpoint_path, \n",
    "                          output_node_names=\"y_\", restore_op_name=\"save/restore_all\",\n",
    "                          filename_tensor_name=\"save/Const:0\", \n",
    "                          output_graph=output_frozen_graph_name, clear_devices=True, initializer_nodes=\"\")\n",
    "        \n",
    "\n",
    "    if job_name == \"ps\":\n",
    "        print_log(worker_num, \"Parameter Server Joining\")\n",
    "        server.join()\n",
    "\n",
    "    elif job_name == \"worker\":\n",
    "        print_log(worker_num, \"worker {0} starting\")\n",
    "\n",
    "        with tf.device(tf.train.replica_device_setter(\n",
    "                worker_device=\"/job:worker/task:%d\" % task_index,\n",
    "                cluster=cluster)):\n",
    "\n",
    "            ################  The computational graph ########################\n",
    "\n",
    "            # Queue parameters\n",
    "            num_epochs = 1 if args.mode == \"inference\" else None if args.epochs == 0 else args.epochs\n",
    "            index = task_index if args.mode == \"inference\" else None\n",
    "            workers = num_workers if args.mode == \"inference\" else None\n",
    "\n",
    "            # Placeholders or QueueRunner/Readers for input data\n",
    "            features = TFNode.hdfs_path(ctx, args.features)  # input csv files\n",
    "            labels = TFNode.hdfs_path(ctx, args.labels)  # input csv files\n",
    "            test_features = TFNode.hdfs_path(ctx, args.testfeatures)  # input csv files\n",
    "            test_labels = TFNode.hdfs_path(ctx, args.testlabels)  # input csv files\n",
    "\n",
    "            # Read input from queues\n",
    "            x = read_csv_features(features, batch_size, num_epochs, index, workers)\n",
    "            x = tf.reshape(x, [x.shape[0].value, SEQUENCE_SIZE, NUM_FEATURES])\n",
    "            y = read_csv_labels(labels, batch_size, num_epochs, index, workers)\n",
    "            x_test = read_csv_features(test_features, batch_size, num_epochs, index, workers)\n",
    "            x_test = tf.reshape(x_test, [x_test.shape[0].value, SEQUENCE_SIZE, NUM_FEATURES])\n",
    "            y_test = read_csv_labels(test_labels, batch_size, num_epochs, index, workers)\n",
    "\n",
    "            # First FCC layer\n",
    "            W = {\n",
    "                'hidden': tf.Variable(tf.random_normal([NUM_FEATURES, NUM_HIDDEN_UNITS])),\n",
    "                'output': tf.Variable(tf.random_normal([NUM_HIDDEN_UNITS, NUM_CLASSES]))\n",
    "            }\n",
    "            biases = {\n",
    "                'hidden': tf.Variable(tf.random_normal([NUM_HIDDEN_UNITS], mean=1.0)),\n",
    "                'output': tf.Variable(tf.random_normal([NUM_CLASSES]))\n",
    "            }\n",
    "\n",
    "            # Reshape for convenience\n",
    "            X = tf.transpose(x, [1, 0, 2])\n",
    "            X = tf.reshape(X, [-1, NUM_FEATURES])\n",
    "            X_test = tf.transpose(x_test, [1, 0, 2])\n",
    "            X_test = tf.reshape(X_test, [-1, NUM_FEATURES])\n",
    "\n",
    "            # Output from first FCC layer, split into sequences for truncated backprop\n",
    "            hidden = tf.nn.relu(tf.matmul(X, W['hidden']) + biases['hidden'])\n",
    "            hidden = tf.split(hidden, SEQUENCE_SIZE, 0)\n",
    "            hidden_test = tf.nn.relu(tf.matmul(X_test, W['hidden']) + biases['hidden'])\n",
    "            hidden_test = tf.split(hidden_test, SEQUENCE_SIZE, 0)\n",
    "\n",
    "            # Stack 2 LSTM layers\n",
    "            lstm_layers = [tf.contrib.rnn.BasicLSTMCell(NUM_HIDDEN_UNITS, forget_bias=1.0) for _ in range(2)]\n",
    "            lstm_layers = tf.contrib.rnn.MultiRNNCell(lstm_layers)\n",
    "\n",
    "            # Get output from LSTM layers\n",
    "            outputs, _ = tf.contrib.rnn.static_rnn(lstm_layers, hidden, dtype=tf.float32)\n",
    "            outputs_test, _ = tf.contrib.rnn.static_rnn(lstm_layers, hidden_test, dtype=tf.float32)\n",
    "\n",
    "            # Get output for the last time step\n",
    "            lstm_last_output = outputs[-1]\n",
    "            lstm_last_output_test = outputs_test[-1]\n",
    "\n",
    "            # Output from second FCC layer, aka logits\n",
    "            logits = tf.matmul(lstm_last_output, W['output']) + biases['output']\n",
    "            logits_test = tf.matmul(lstm_last_output_test, W['output']) + biases['output']\n",
    "\n",
    "            # Global step to keep track of how long training have proceeded\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "            # Make predictions with softmax + argmax\n",
    "            softmax_prediction = tf.nn.softmax(logits, name=\"prediction\")\n",
    "            prediction = tf.argmax(softmax_prediction, 1)\n",
    "            softmax_prediction_test = tf.nn.softmax(logits_test, name=\"prediction_test\")\n",
    "            prediction_test = tf.argmax(softmax_prediction_test, 1)\n",
    "\n",
    "            # L2 Regularization\n",
    "            L2_LOSS = 0.0015\n",
    "            l2 = L2_LOSS * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "\n",
    "            # Cross entropy loss + L2 regularization\n",
    "            loss = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    labels=tf.one_hot(tf.reshape(y, [-1]), NUM_CLASSES),\n",
    "                    logits=logits))\n",
    "            loss_test = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    labels=tf.one_hot(tf.reshape(y_test, [-1]), NUM_CLASSES),\n",
    "                    logits=logits_test))\n",
    "            loss_reg = loss + l2\n",
    "            tf.summary.scalar(\"loss_test\", loss_test)  # for tensorboard\n",
    "\n",
    "            # Define optimizer\n",
    "            opt = tf.train.AdamOptimizer(0.5)\n",
    "            opt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=num_workers,\n",
    "                                                     total_num_replicas=num_workers)\n",
    "            train_step = opt.minimize(loss_reg, global_step=global_step)\n",
    "            \n",
    "            # TF boilerplate for Sync-SGD\n",
    "            sync_replicas_hook = opt.make_session_run_hook(task_index == 0)\n",
    "            chief_queue_runner = opt.get_chief_queue_runner()\n",
    "\n",
    "            # Test trained model\n",
    "            correct_prediction = tf.equal(prediction, tf.argmax(tf.one_hot(tf.reshape(y, [-1]), NUM_CLASSES), 1))\n",
    "            correct_prediction_test = tf.equal(prediction_test, tf.argmax(tf.one_hot(tf.reshape(y_test, [-1]), NUM_CLASSES),1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "            accuracy_test = tf.reduce_mean(tf.cast(correct_prediction_test, tf.float32), name=\"accuracy_test\")\n",
    "            tf.summary.scalar(\"acc_test\", accuracy_test)  # for tensorboard\n",
    "\n",
    "            # Utility stuff tensorboard and logging\n",
    "            saver = tf.train.Saver()\n",
    "            summary_op = tf.summary.merge_all()\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            logdir = tensorboard.logdir()\n",
    "            display_step = 200\n",
    "            history = dict(test_loss=[], test_acc=[], log = [])\n",
    "            print_log(worker_num, \"tensorflow model path: {0}\".format(logdir))\n",
    "\n",
    "            # Setup Supervisor\n",
    "            if job_name == \"worker\" and task_index == 0:\n",
    "                summary_writer = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())\n",
    "\n",
    "            if args.mode == \"train\":\n",
    "                sv = tf.train.Supervisor(is_chief=(task_index == 0),\n",
    "                                         logdir=logdir,\n",
    "                                         init_op=init_op,\n",
    "                                         summary_op=None,\n",
    "                                         summary_writer=None,\n",
    "                                         saver=saver,\n",
    "                                         global_step=global_step,\n",
    "                                         stop_grace_secs=300,\n",
    "                                         save_model_secs=10)\n",
    "            else:\n",
    "                sv = tf.train.Supervisor(is_chief=(task_index == 0),\n",
    "                                         logdir=logdir,\n",
    "                                         summary_op=None,\n",
    "                                         saver=saver,\n",
    "                                         global_step=global_step,\n",
    "                                         stop_grace_secs=300,\n",
    "                                         save_model_secs=0)\n",
    "\n",
    "    # Run the graph for NUM_STEPS, compute test accuracy incrementally\n",
    "    # The supervisor takes care of session initialization, restoring from\n",
    "    # a checkpoint, and closing when done or an error occurs.\n",
    "    with sv.managed_session(server.target) as sess:\n",
    "        \"\"\"Synchronous SGD training with supervisor\"\"\"\n",
    "        if sv.is_chief:\n",
    "                    sv.start_queue_runners(sess, [chief_queue_runner])\n",
    "                \n",
    "        print_log(worker_num, \"session ready, starting training\")\n",
    "        step = 0\n",
    "        while not sv.should_stop() and step < args.steps:\n",
    "            if args.mode == \"train\":\n",
    "                _, summary, step = sess.run([train_step, summary_op, global_step])\n",
    "                if(step % 50 == 0):\n",
    "                    print(\"step: {0}\".format(step))\n",
    "                if(step % display_step == 0):\n",
    "                    test_a, test_l = sess.run([accuracy_test, loss_test])\n",
    "                    result = \"step: {0}, test acc: {1}, test loss: {2}\".format(step, test_a, test_l)\n",
    "                    history['test_loss'].append(test_l)\n",
    "                    history['test_acc'].append(test_a)\n",
    "                    history['log'].append(result)\n",
    "                    print_log(worker_num, result)\n",
    "                    if sv.is_chief:\n",
    "                        summary_writer.add_summary(summary, step)\n",
    "            else:\n",
    "                print_log(worker_num, \"inference not supported, do it locally with saved model instead\")\n",
    "\n",
    "        if args.mode == \"inference\":\n",
    "            print_log(worker_num, \"inference not supported, do it locally with saved model instead\")\n",
    "\n",
    "        if sv.is_chief:\n",
    "            print_log(worker_num, \"Saving session stats\")\n",
    "            endTime = datetime.now()\n",
    "            timeElapsed= endTime-startTime\n",
    "            accs = \"\\n\".join(str(x) for x in history[\"test_acc\"])\n",
    "            loss = \"\\n\".join(str(x) for x in history[\"test_loss\"])\n",
    "            logs = \"\\n\".join(str(x) for x in history[\"log\"])\n",
    "            pyhdfs.dump(accs, args.output + \"/accuracy\")\n",
    "            pyhdfs.dump(loss, args.output + \"/loss\")\n",
    "            pyhdfs.dump(logs, args.output + \"/log\")\n",
    "            time = \"start: \" + str(startTime) + \"\\nend: \" + str(endTime) + \"\\nduration: \" + str(timeElapsed)\n",
    "            pyhdfs.dump(time, args.output + \"/time\")\n",
    "            summ = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())\n",
    "            summ.flush()\n",
    "\n",
    "        # Ask for all the services to stop.\n",
    "        print(\"{0} stopping supervisor\".format(datetime.now().isoformat()))\n",
    "        sv.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Spark Cluster Setup For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tSession 3355 unexpectedly reached final status 'dead'. See logs:\n",
      "stdout: \n",
      "17/12/23 14:50:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "17/12/23 14:50:04 INFO RMProxy: Connecting to ResourceManager at /10.0.104.190:8032\n",
      "17/12/23 14:50:04 INFO Client: Requesting a new application from cluster with 30 NodeManagers\n",
      "17/12/23 14:50:04 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (216000 MB per container)\n",
      "17/12/23 14:50:04 INFO Client: Will allocate AM container, with 56320 MB memory including 5120 MB overhead\n",
      "17/12/23 14:50:04 INFO Client: Setting up container launch context for our AM\n",
      "17/12/23 14:50:04 INFO Client: Setting up the launch environment for our AM container\n",
      "17/12/23 14:50:04 INFO Client: Preparing resources for our AM container\n",
      "17/12/23 14:50:05 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "17/12/23 14:50:08 INFO Client: Uploading resource file:/tmp/spark-a69376fc-cab3-4c36-9636-52debcd8817e/__spark_libs__7906098837884017942.zip -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/__spark_libs__7906098837884017942.zip\n",
      "17/12/23 14:50:09 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/livy-rsc-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/livy-rsc-0.4.0-SNAPSHOT.jar\n",
      "17/12/23 14:50:09 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/netty-all-4.0.29.Final.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/netty-all-4.0.29.Final.jar\n",
      "17/12/23 14:50:09 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/livy-api-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/livy-api-0.4.0-SNAPSHOT.jar\n",
      "17/12/23 14:50:09 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/livy-repl_2.11-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/livy-repl_2.11-0.4.0-SNAPSHOT.jar\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/livy-core_2.11-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/livy-core_2.11-0.4.0-SNAPSHOT.jar\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/commons-codec-1.9.jar -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/commons-codec-1.9.jar\n",
      "17/12/23 14:50:10 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/har_2__kimham00/har_2__kimham00__kstore.jks#k_certificate\n",
      "17/12/23 14:50:10 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/har_2__kimham00/har_2__kimham00__tstore.jks#t_certificate\n",
      "17/12/23 14:50:10 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/spark/log4j.properties\n",
      "17/12/23 14:50:10 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/har_2__kimham00/har_2__kimham00__cert.key#material_passwd\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/srv/hops/spark/python/lib/pyspark.zip -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/pyspark.zip\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/srv/hops/spark/python/lib/py4j-0.10.4-src.zip -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/py4j-0.10.4-src.zip\n",
      "17/12/23 14:50:10 WARN Client: Same path resource file:/srv/hops/spark/python/lib/pyspark.zip added multiple times to distributed cache.\n",
      "17/12/23 14:50:10 WARN Client: Same path resource file:/srv/hops/spark/python/lib/py4j-0.10.4-src.zip added multiple times to distributed cache.\n",
      "17/12/23 14:50:10 INFO Client: Uploading resource file:/tmp/spark-a69376fc-cab3-4c36-9636-52debcd8817e/__spark_conf__232271761179586674.zip -> hdfs:/Projects/har_2/Resources/.sparkStaging/application_1513605045578_0638/__spark_conf__.zip\n",
      "17/12/23 14:50:10 INFO SecurityManager: Changing view acls to: livy,har_2__kimham00\n",
      "17/12/23 14:50:10 INFO SecurityManager: Changing modify acls to: livy,har_2__kimham00\n",
      "17/12/23 14:50:10 INFO SecurityManager: Changing view acls groups to: \n",
      "17/12/23 14:50:10 INFO SecurityManager: Changing modify acls groups to: \n",
      "17/12/23 14:50:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(livy, har_2__kimham00); groups with view permissions: Set(); users  with modify permissions: Set(livy, har_2__kimham00); groups with modify permissions: Set()\n",
      "17/12/23 14:50:10 INFO Client: Submitting application application_1513605045578_0638 to ResourceManager\n",
      "17/12/23 14:50:10 INFO YarnClientImpl: Submitted application application_1513605045578_0638\n",
      "17/12/23 14:50:10 INFO Client: Application report for application_1513605045578_0638 (state: ACCEPTED)\n",
      "17/12/23 14:50:11 INFO Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: AM container is launched, waiting for AM container to Register with RM\n",
      "\t ApplicationMaster host: N/A\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: default\n",
      "\t start time: 1514037010972\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://hadoop30:8088/proxy/application_1513605045578_0638/\n",
      "\t user: har_2__kimham00\n",
      "17/12/23 14:50:11 INFO ShutdownHookManager: Shutdown hook called\n",
      "17/12/23 14:50:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-a69376fc-cab3-4c36-9636-52debcd8817e\n",
      "\n",
      "stderr: \n",
      "\n",
      "YARN Diagnostics: \n",
      "YARN Diagnostics:\n",
      "Application application_1513605045578_0638 failed 1 times (global limit =2; local limit is =1) due to AM Container for appattempt_1513605045578_0638_000001 exited with  exitCode: -1\n",
      "Failing this attempt.Diagnostics: Failed to create cgroup at /sys/fs/cgroup/devices/hops-yarn/container_e28_1513605045578_0638_01_000001\n",
      "For more detailed output, check the application tracking page: http://hadoop30:8088/cluster/app/application_1513605045578_0638 Then click on links to logs of each attempt.\n",
      ". Failing the application..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from hops import util\n",
    "from hops import hdfs\n",
    "\n",
    "from tensorflowonspark import TFCluster\n",
    "\n",
    "project_path = \"/Projects/\" + hdfs.project_name()\n",
    "\n",
    "TRAIN_FEATURES_PATH = project_path + \"/HAR_Dataset/cleaned_data_parallel/train/features\"\n",
    "TRAIN_LABELS_PATH = project_path + \"/HAR_Dataset/cleaned_data_parallel/train/labels\"\n",
    "TEST_FEATURES_PATH = project_path + \"/HAR_Dataset/cleaned_data_parallel/test/features\"\n",
    "TEST_LABELS_PATH = project_path + \"/HAR_Dataset/cleaned_data_parallel/test/labels\"\n",
    "OUTPUT_PATH = project_path + \"/HAR_Dataset/output/dist_sync\"\n",
    "MODEL_PATH = project_path + \"/HAR_Dataset/output/dist_sync/saved_model\"\n",
    "\n",
    "sc = spark.sparkContext\n",
    "num_executors = util.num_executors(spark)\n",
    "num_ps = util.num_param_servers(spark)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--epochs\", help=\"number of epochs\", type=int, default=1000000)\n",
    "parser.add_argument(\"-f\", \"--format\", help=\"example format: (csv|pickle|tfr)\", choices=[\"csv\",\"pickle\",\"tfr\"], default=\"csv\")\n",
    "parser.add_argument(\"-fe\", \"--features\", help=\"HDFS path to MNIST images in parallelized format\", default=TRAIN_FEATURES_PATH)\n",
    "parser.add_argument(\"-l\", \"--labels\", help=\"HDFS path to MNIST labels in parallelized format\", default=TRAIN_LABELS_PATH)\n",
    "parser.add_argument(\"-tf\", \"--testfeatures\", help=\"HDFS path to features in parallelized format\", default=TEST_FEATURES_PATH)\n",
    "parser.add_argument(\"-tl\", \"--testlabels\", help=\"HDFS path to labels in parallelized format\", default=TEST_LABELS_PATH)\n",
    "parser.add_argument(\"-m\", \"--model\", help=\"HDFS path to save/load model during train/inference\", default=MODEL_PATH)\n",
    "parser.add_argument(\"-n\", \"--cluster_size\", help=\"number of nodes in the cluster (for Spark Standalone)\", type=int, default=num_executors)\n",
    "parser.add_argument(\"-o\", \"--output\", help=\"HDFS path to save test/inference output\", default=OUTPUT_PATH)\n",
    "parser.add_argument(\"-r\", \"--readers\", help=\"number of reader/enqueue threads\", type=int, default=1)\n",
    "parser.add_argument(\"-s\", \"--steps\", help=\"maximum number of steps\", type=int, default=2001)\n",
    "parser.add_argument(\"-tb\", \"--tensorboard\", help=\"launch tensorboard process\", action=\"store_true\")\n",
    "parser.add_argument(\"-X\", \"--mode\", help=\"train|inference\", default=\"train\")\n",
    "parser.add_argument(\"-c\", \"--rdma\", help=\"use rdma connection\", default=False)\n",
    "parser.add_argument(\"-lr\", \"--learningrate\", help=\"number of epochs\", type=float, default=0.00025)\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"{0} ===== Start\".format(datetime.now().isoformat()))\n",
    "\n",
    "cluster = TFCluster.run(sc, map_fun, args, args.cluster_size, num_ps, args.tensorboard, TFCluster.InputMode.TENSORFLOW)\n",
    "cluster.shutdown()\n",
    "\n",
    "print(\"{0} ===== Stop\".format(datetime.now().isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
